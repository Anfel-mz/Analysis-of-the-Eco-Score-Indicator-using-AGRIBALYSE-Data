# -*- coding: utf-8 -*-
"""Projet FMD

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UgGeF0DdR1tXD_gNQA_eQtStQ15FoHEu
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np

#Question 1
import pandas as pd
file_path = '/content/drive/MyDrive/AGRIBALYSE3.1_partie agriculture_conv_vf.xlsx'
exc = pd.ExcelFile(file_path)
df = pd.read_excel(exc, 'AGB_agri_conv', usecols = [0]+[i for i in range(3,20)])
data = df[2:].values

#Question 2 : Normalisation
L_fnorm=[7.55e3,5.23e-2,4.22e3,4.09e1,5.95e-4,1.29e-4,
         1.73e-5,5.56e1,1.61,1.95e1,1.77e2,5.67e4,
         8.19e5,1.15e4,6.5e4,6.36e-2]
data_i=data #sauvegarde des données initiales dans data_i
data=data[:,2:]
for i in range(16):
  data[:,i]=data[:,i]/L_fnorm[i]

#Question 3
import matplotlib.pyplot as plt

#critère 1 et 14
plt.scatter(list(data[:,0]), list(data[:,13]), label='corrélation entre le critère déréglement climatique et épuisement des resources en eau', c='red')
plt.legend()
plt.xlabel('score déréglement climatique')
plt.ylabel('score épuisement des resources en eau')
plt.show()

# critère 1 et 16
plt.scatter(list(data[:,0]), list(data[:,15]), label='corrélation entre le critère déréglement climatique et épuisement des resources matières', c='blue')
plt.legend()
plt.xlabel('score déréglement climatique')
plt.ylabel('score épuisement des resources matières')
plt.show()

plt.scatter(list(data[:,13]), list(data[:,15]), label='corrélation entre le critère épuisement des resources en eau et épuisement des resources matières', c='green')
plt.legend()
plt.xlabel('score épuisement des resources en eau')
plt.ylabel('score épuisement des resources matières')
plt.show()

# Question 5
def pareto_domine (X,Y):
  test1=1
  test2=0
  for i in range(len(X)): 
    if X[i]>Y[i]:
      test1=0
    if X[i]<Y[i]:
      test2=1

  return (test1 and test2)

# Question 6

# Nous allons créer deux fonctions utiles pour vérifier les propriétés.

# pd_couple retourne une liste des couples (X,Y) tels que X pareto domine Y
def pd_couple(data):
  n= data.shape[0]
  l=[]
  for  i in range(n):
    L=[k for k in range(n)]
    L.remove(i)
    for j in L :
      if pareto_domine(data[i,:],data[j,:]):
        l.append((data[i,:],data[j,:]))
  for x, y in l : 
    if(x.all() == y.all()) :
      l=[(z,w) for (z,w) in l if (z.all() != x.all() and y.all() != w.all())]
  return l

# pd_jointure retourne une liste des triplets (X,Y,Z) tels que (X PD Y) et (Y PD Z)
def pd_jointure(data):
  l=[]
  l1=pd_couple(data)
  for c1 in l1:
    for c2 in l1:
      if c1[1].all()==c2[0].all():
        l.append((c1[0],c1[1],c2[1]))
  return l

# Méthodes de Vérification des propriétés 

def trans(triplets) : #cette fonction prend une liste des (X,Y,Z) tel que (X PD Y) et (Y PD Z)
  for X, Y,Z in triplets:
    if not(pareto_domine(X,Z)) : 
      return False
  return True


def asym(relation):  # cette fonction prend une liste des (X,Y) tel que X PD Y
  for X,Y in relation:
    if pareto_domine(Y,X):
      return False
  return True

def anti_sym(relation):   # cette fonction prend une liste des (X,Y) tel que X PD Y
  for X,Y in relation:
    if (pareto_domine(Y,X)) and (X.all() != Y.all()):
      return False
  return True

def irreflexive(relation):    # cette fonction prend une liste des (X,Y) tel que X PD Y
  for c in relation:
    X=c[0]
    Y=c[1]
    if X.all() == Y.all():
      return False
  return True

l= pd_jointure(data)

trans(l)

c=pd_couple(data)

asym(c)

anti_sym(c)

irreflexive(c)

#Question 7 : calcul du pourcentage de couples qui vérifient la pareto dominance 

n = data.shape[0]
N =  n * (n-1) #nombre total des couples

def pourcentage_pd(data):
  c=0                   #compteur des couples qui vérifient la pareto dominance
  for  i in range(n):
    for j in range(n-1):
      if pareto_domine(data[i,:], data[j,:]):
        c+=1 
  print ("le pourcentage de couple (X,Y) tel que X pareto domine Y : ", c/N)

print ('Calcul sur tous les critères : \n ')
pourcentage_pd(data)

print ('\nCalcul sur les critère 1, 14 et 16 : \n')
pourcentage_pd(data[:, [0,13,15]])

#Question 10

w1= np.array([21.06e-2,6.31e-2,5.01e-2,4.78e-2,8.96e-2,1.84e-2,2.13e-2,6.2e-2,2.8e-2,2.96e-2,3.61e-2,1.92e-2,7.94e-2,8.51e-2,8.32e-2,7.55e-2])
def sp(X,w):
  return (sum(X*w))

!pip install mip

from mip import *

def L1_inv(X,Y):
  if sp(X, w1) < sp(Y,w1):
 
    model = Model()

    # Définition des variables de décision
    w2 =[model.add_var(lb=0) for i in range(16)]
    y =[model.add_var(lb=0) for i in range(16)]
    t=[model.add_var(lb=0) for i in range(16)]
    # Définition de la fonction objectif
    model.objective = minimize(xsum(y[i]+t[i] for i in range(16)))

    # Ajout des contraintes
    model += (xsum(w2[i] for i in range(16))==1)
    model += (sp(X, w2) >= sp(Y, w2))

    for i in range(16):
      model += w2[i]-w1[i] == y[i] - t[i] 

    # Résolution du modèle
    model.optimize()
    return model.objective_value
  else: return

#Question 11

def sp_couple(data):
  n= data.shape[0]
  l=[]
  for  i in range(n):
    L=[k for k in range(n)]
    L.remove(i)
    for j in L :
      if sp(data[i,:],w1) < sp(data[j,:], w1):
        l.append((data[i,:],data[j,:]))
  return l

# Liste des abscisses
Lx=[]
for c in sp_couple(data):
  v=L1_inv(c[0],c[1])
  if v!=None:  
    if (v>=0) and v<=2 :
      Lx.append(v)
Lx.sort()

# Liste des ordonnées
Ly=[ i for i in range(1,len (Lx)+1)]

def graph_show (Lx, Ly):
  plt.plot(Lx, Ly)
  plt.legend()
  plt.xlabel('Valeurs de L1_inv entre 0 et 2')
  plt.ylabel('Nombre de couples (X,Y) tel que l1_inv(X,Y)<=x ')
  plt.show()
graph_show(Lx,Ly)

#Question 12
def MPO(w,X):
  X.sort()
  return sum(X*w)

def MG(w,X):
  K=len(X)
  L=np.array([X[i]**w[i] for i in range(K)])
  return (np.prod(L))**(1/sum(w))

# Jeu de poids w2 à coefficients croissants et aléatoires et tel que la somme des poids = 1
import random

n = 16
liste = [0.0]

for i in range(n-1):
    r = random.uniform(0, 1)
    liste.append(liste[-1] + r)

# Normalisation des valeurs pour que la somme soit = 1

w2= [x/sum(liste) for x in liste]

# Jeu de poids w3 à coefficients décroissants et aléatoires et tel que la somme des poids = 1

liste = [0.0]

for i in range(n-1):
    r = random.uniform(0, 1)
    liste.append(liste[-1] + r)

# Normalisation des valeurs pour que la somme soit = 1

w3= [x/sum(liste) for x in liste]
w3.reverse()

#Jeu w4 de poids à coefficients aléatoires dont la somme =1

n=16
liste=[0.0]

for i in range(n-1):
  r=random.uniform(0,1)
  liste.append(r)

w4 = [x/sum(liste) for x in liste]

#Question 15

#Retourne une liste de  tous les couples X,Y de data
def couple(data):
  n= data.shape[0]
  l=[]
  for  i in range(n):
    L=[k for k in range(n)]
    L.remove(i)
    for j in L :
      l.append((data[i,:],data[j,:]))
  return l

# Méthode pour le calcul des distances de Kendall-Tau pour un jeu de poids w
def DKT (w):
  rslt = 0
  for X, Y in couple(data): 
    rslt = rslt + 0.5 * int((MPO(w,X)<MPO(w,Y) and MG(w,Y)<MG(w,X))) + 0.5 *int(((MPO(w,X)<MPO(w,Y) and not(MG(w,X)<MG(w,Y))) or (not((MPO(w,X)<MPO(w,Y))) and MG(w,X)<MG(w,Y))))
  return rslt

# Jeu de poids w1 : initial
DKT(w1)

# Jeu de poids w2 à coefficients croissants et aléatoires et tel que la somme des poids = 1
DKT(w2)

# Jeu de poids w3 décroissants et aléatoires 
DKT(w3)

#Question 16

# Méthode pour le calcul du score
def score(x) : 
  return 100 - (np.log(10*x+1)/np.log(2+1/(100*x**4)))*20

# Méthode pour la categorie d'un aliment grâce au calcul du score

def categorie(x) : 
  s =  score(x)
  if s >=0 and s <= 20 :
    return ("E") 
  if s >20 and s <= 40 :
    return ("D") 
  if s >40 and s <= 60 :
    return ("C")
  if s >60 and s <= 80 :
    return ("B")
  if s >80 and s <= 100 :
    return ("A") 
  else : 
    return

#Tous les aliments sont de la catégorie A

for i in range(data.shape[0]) : 
  if categorie(sp(data[i,:],w4)) != "A" : 
    print(categorie(sp(data[i,:],w4)))

#Question 17

# PL modifié de la question 9 
def L1_inv2(X):
  model = Model()
  n = X.shape[0]
  # Définition des variables de décision
  w2 =[model.add_var(lb=0) for i in range(n)]
  y =[model.add_var(lb=0) for i in range(n)]
  t=[model.add_var(lb=0) for i in range(n)]
  # Définition de la fonction objectif
  model.objective = minimize(xsum(y[i]+t[i] for i in range(n)))

  # Ajout des contraintes
  model += (xsum(w2[i] for i in range(n))==1)
  model += (sp(X,w2) >= 0.28) # Nouvelle contrainte de changement de catégorie, 0.28 correspond à la borne inférieur de la catA

  for i in range(n):
    model += w2[i]-w1[i] == y[i] - t[i] 

  # Résolution du modèle
  model.optimize()
  # Renvoyer la valeur optimale de la fonction objectif et la valeur optimale de w2
  return model.objective_value

# Liste des abscisses
Lx=[]
for i in range (data.shape[0]):
  v = L1_inv2(data[i,:])
  if v!=None:  
    Lx.append(v)
Lx.sort()

# Liste des ordonnées
Ly=[ i for i in range(1,len (Lx)+1)]
graph_show(Lx,Ly)